{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions Used\n",
    "- **IPython:** 5.1.0\n",
    "- **tensorflow:** 1.2.1\n",
    "- **numpy:** 1.12.1\n",
    "- **pandas:** 0.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython: 5.1.0\n",
      "tensorflow: 1.2.1\n",
      "numpy: 1.13.1\n",
      "pandas: 0.20.2\n"
     ]
    }
   ],
   "source": [
    "#Checking the versions\n",
    "import IPython\n",
    "print('IPython:', IPython.__version__)\n",
    "import tensorflow\n",
    "print('tensorflow:', tensorflow.__version__)\n",
    "import numpy\n",
    "print('numpy:', numpy.__version__)\n",
    "import pandas\n",
    "print('pandas:', pandas.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensorflow\n",
    "A computational graph is a series of TensorFlow operations arranged into a graph of nodes. Let's build a simple computational graph. Each node takes zero or more tensors as inputs and produces a tensor as an output.\n",
    "![Tensor Graph](img/tensor-graph.jpg)\n",
    "The graph above helps understand the basics of tensorflow.The graph has two input nodes(ie. node-A and node-B) where two different constant values(ie. 7 and 10) are passed. The values are passed to intermediary nodes(ie. node-C and node-D). Node-C performs addition operation on input values while node-D performs multipilcation. The values from both the nodes(C and D) are passed down to node-E where modulus operation takes place and the output is presented\n",
    "Now, lets describe the different components of the graph.\n",
    "- **Nodes:**They are typically drawn as circles, ovals, or boxes, represent some sort of computation or action being done on or with data in the graph’s context. In the above example, the operation “add” is the sole node.\n",
    "\n",
    "- **Edges/Tensors:**They are the actual values that get passed to and from Operations, and are typically drawn as arrows. In the “add” example, the inputs 1 and 2 are both edges leading into the node, while the output 3 is an edge leading out of the node. Conceptually, we can think of edges as the link between different Operations as they carry information from one node to the next. The central unit of data in TensorFlow is the tensor. A tensor consists of a set of primitive values shaped into an array of any number of dimensions. A tensor's rank is its number of dimensions. Here are some examples of tensors:\n",
    "\n",
    "- 3 # a rank 0 tensor; this is a scalar with shape []\n",
    "- [1. ,2., 3.] # a rank 1 tensor; this is a vector with shape [3]\n",
    "- [[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]\n",
    "\n",
    "For more about Tensor Ranks, Shapes, and Types: https://www.tensorflow.org/programmers_guide/dims_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing TensorFlow\n",
    "#This gives Python access to all of TensorFlow's classes, methods, and symbols\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now transform the graph above to a tensorflow model. \n",
    "#Define the nodes first\n",
    "\n",
    "node_a = tf.constant(7.0, name='input_a')\n",
    "node_b = tf.constant(10.0, name='input_b')\n",
    "node_c = tf.add(node_a,node_b, name='add_c')\n",
    "node_d = tf.multiply(node_a,node_b, name='mul_d')\n",
    "node_e = tf.mod(node_d,node_c, name='mod_e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datatype here is by default float32. it can be changed by explicitly as an argument while creating node. Check the tensorflow documentation for details about the arguments.\n",
    "- Tensorflow documentation : https://www.tensorflow.org/api_docs/python/\n",
    "- Goto this link for more math functions : https://www.tensorflow.org/api_guides/python/math_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_a:0\", shape=(), dtype=float32) Tensor(\"mod_e:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(node_a, node_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that printing the nodes does not output the values 7.0 and 2.0 as you might expect. Instead, they are nodes that, when evaluated, would produce 7.0 and 2.0, respectively. To actually evaluate the nodes, we must run the computational graph within a session. A session encapsulates the control and state of the TensorFlow runtime.\n",
    "The following code creates a Session object and then invokes its run method to run enough of the computational graph to evaluate node-A and node-E. By running the computational graph in a session as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.0, 2.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run([node_a, node_e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you can also run a single node\n",
    "sess.run(node_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you can also assign a node output to a variable\n",
    "output = sess.run(node_d)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can aslo visualize the graph to confirm that if it’s structured the same way we drew it out. To do that, we use **TensorBoard**. But first, we are creating a TensorFlow **FileWriter** object, and assigning it to the variable **write**. This command creates a folder named **graph** alongside the python file we've written and the summary is placed inside that folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter ( './graph' , sess.graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to your terminal and type in the following command:\n",
    "- **tensorboard --logdir=\"graph\"**\n",
    "\n",
    "Make sure that your present working directory is thesame as where you ran your Python code. Then, open your browser and go to http://localhost:6006/ (or the link you get back after running tensorboard command). The screenshot of the graphical interface and graphs are shown below.\n",
    "![Graphical Interface](img/graphical-interface.jpg) ![Graph](img/graph.jpg)\n",
    "Though the graph doesn't look exactly like the graph we previously drew, its the same. The inputs(A and B) to the multipication and addition blocks are just duplicated in this version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Once you are done constructing your graph, its a good habit to close the Session and FileWriter\n",
    "writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To avoid having to close session everytime, you can define them in a **with** block. So after running the **with** block, the session will automatically close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    output = sess.run(node_d)\n",
    "    print(output)\n",
    "    #writer can also be defined within this session as follows\n",
    "    #writer = tf.summary.FileWriter ( './graph' , sess.graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional array in Tensorflow(Rank and shape of a Tensor)\n",
    "TensorFlow programs use a tensor data structure to represent all data. You can think of a TensorFlow tensor as an n-dimensional array or list. A tensor has a static type and dynamic dimensions. Only tensors may be passed between nodes in the computation graph.\n",
    "\n",
    "### Tensor Rank\n",
    "In the TensorFlow system, tensors are described by a unit of dimensionality known as rank. Tensor rank is not the same as matrix rank. Tensor rank (sometimes referred to as order or degree or n-dimension) is the number of dimensions of the tensor.For example, the following tensor (defined as a Python list) has a rank of 2:\n",
    "- t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "A rank two tensor is what we typically think of as a matrix, a rank one tensor is a vector. For a rank two tensor you can access any element with the syntax t[i, j]. For a rank three tensor you would need to address an element with t[i, j, k].\n",
    "![Tensor Rank](img/tensor-rank.jpg)\n",
    "\n",
    "### Tensor Shape\n",
    "The TensorFlow documentation uses three notational conventions to describe tensor dimensionality: rank, shape, and dimension number. The following table shows how these relate to one another:\n",
    "![Tensor Shape](img/tensor-shape.jpg)\n",
    "\n",
    "Now, lets try and code different tensors in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar(0-D tensor) \n",
      " [1]\n",
      "Vector(1-D tensor with shape [3]) \n",
      " [1 2 3 4]\n",
      "Matrix(2-D tensor with shape [3,3] ie.3*3 matrix) \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Tensor(3-D tensor with shape [3,3,3]) \n",
      " [[[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]\n",
      "\n",
      " [[4 2 7]\n",
      "  [1 9 3]\n",
      "  [2 4 5]]\n",
      "\n",
      " [[9 2 8]\n",
      "  [3 7 1]\n",
      "  [0 5 6]]]\n"
     ]
    }
   ],
   "source": [
    "scalar = tf.constant([1])\n",
    "vector = tf.constant([1,2,3,4])\n",
    "matrix = tf.constant([[1,2,3],[4,5,6],[7,8,9]])\n",
    "tensor = tf.constant([[[1,2,3],[4,5,6],[7,8,9]], [[4,2,7],[1,9,3],[2,4,5]], [[9,2,8],[3,7,1],[0,5,6]]])    \n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(scalar)\n",
    "    print('Scalar(0-D tensor) \\n', result)\n",
    "    result = sess.run(vector)\n",
    "    print('Vector(1-D tensor with shape [3]) \\n', result)\n",
    "    result = sess.run(matrix)\n",
    "    print('Matrix(2-D tensor with shape [3,3] ie.3*3 matrix) \\n', result)\n",
    "    result = sess.run(tensor)\n",
    "    print('Tensor(3-D tensor with shape [3,3,3]) \\n', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables & Placeholders\n",
    "A graph can be parameterized to accept external inputs, known as placeholders. A placeholder is a promise to provide a value later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(dtype='float32')\n",
    "# instead of dtype='float32', you can write tf.float32\n",
    "b = tf.placeholder(tf.float32) \n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n",
      "[ 10.    8.5]\n",
      "[[ 10.   4.  11.]\n",
      " [  7.  12.   7.]\n",
      " [  7.  13.  15.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(adder_node, {a: 10, b:2.1}))\n",
    "    print(sess.run(adder_node, {a: [1,3.5], b: [9, 5]}))\n",
    "    print(sess.run(adder_node, {a: [[1,2,3],[4,5,6],[7,8,9]], b: [[9,2,8],[3,7,1],[0,5,6]]}))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computational graph can be made more complex by adding another operation.           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.2\n",
      "[ 20.  17.]\n",
      "[[ 20.   8.  22.]\n",
      " [ 14.  24.  14.]\n",
      " [ 14.  26.  30.]]\n"
     ]
    }
   ],
   "source": [
    "add_and_double = adder_node*2\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(add_and_double, {a: 10, b:2.1}))\n",
    "    print(sess.run(add_and_double, {a: [1,3.5], b: [9, 5]}))\n",
    "    print(sess.run(add_and_double, {a: [[1,2,3],[4,5,6],[7,8,9]], b: [[9,2,8],[3,7,1],[0,5,6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning we typically want a model that can take arbitrary inputs, such as the one above. To make the model trainable, we need to be able to modify the graph to get new outputs with the same input. Variables allow us to add trainable parameters to a graph. They are constructed with a type and initial value as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = tf.Variable([-1], dtype=tf.float32, name='A')\n",
    "b = tf.Variable([1], dtype=tf.float32, name='b')\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "linear_model = A * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants are initialized when you call **tf.constant**, and their value can never change. On the contrary, variables are not initialized when you call **tf.Variable**. To initialize all the variables in a TensorFlow program, you must explicitly call a special operation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to realize **init** is a handle to the TensorFlow sub-graph that initializes all the global variables. Therefore,until we call **sess.run**, the variables are uninitialized.\n",
    "\n",
    "Since **x** is a placeholder, we can evaluate **linear_model** for several values of **x** simultaneously as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  2.  0. -1.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(linear_model, {x:[-2,-1,1,2]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a model(ie.**linear_model**) but we still dont know how good the model is yet. So, to evaluate a model based on training datasets, we need to know the desired values. Lets provide desired values as **y** placeholder.\n",
    "\n",
    "We also need to write a loss function for the model. A loss function measures how far apart the current model is from the provided data. We'll use a standard model for linear regression, which sums the square of the errors between the current model and provided model.(ie. **linear_model-y**).\n",
    "\n",
    "We use **tf.square** to square the error and **tf.reduce_sum** to add all the squared errors to create a single scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.0\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_errors = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_errors)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(loss, {x:[-2,-1,1,2], y:[-6,-4,0,2]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could improve loss value manually by reassigning the values of **A** and **b** to values of **2** and **-2**. A variable is initialized to the value provided to **tf.Variable** but can be changed using operations like **tf.assign**. For example, **A=2** and **b=-2** are the optimal parameters for our model. We can change **W** and **b** accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixA = tf.assign(A, [2.])\n",
    "fixb = tf.assign(b, [-2.])\n",
    "with tf.Session() as sess:\n",
    "    sess.run([fixA, fixb])  \n",
    "    print(sess.run(loss, {x:[-2,-1,1,2], y:[-6,-4,0,2]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We guessed the perfect values of A and b, but the whole idea of machine learning is to find the correct model parameters automatically without having to guess manually. We shall learn to accomplish this in the comming section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers to find correct model parameters\n",
    "Optimiers slowly change each variable(in this case **A** and **b**) in order to minimize **Loss Function**. There are lots of optimizers for our use, but the simplest optimizer is **Gradient Descent**. It modifies each variable according to the magnitude of the derivative of loss with respect to that variable. TensorFlow can automatically produce derivatives given only a description of the model using the function **tf.train.GradientDescentOptimizer()**. A example is shown below to demonstrate how a optimizer works.\n",
    "\n",
    "Note: If you want to get familiar with theoretical part of Gradient Descent and how it works, you can find a lot of materials in the internet and some useful videos in Youtube.\n",
    "\n",
    "wiki link: https://en.wikipedia.org/wiki/Gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[array([-0.40000004], dtype=float32), array([ 0.75999999], dtype=float32)]\n",
      "None\n",
      "[array([ 0.07999995], dtype=float32), array([ 0.53920001], dtype=float32)]\n",
      "None\n",
      "[array([ 0.46399996], dtype=float32), array([ 0.33606404], dtype=float32)]\n",
      "None\n",
      "[array([ 0.77119994], dtype=float32), array([ 0.14917894], dtype=float32)]\n",
      "None\n",
      "[array([ 1.01695991], dtype=float32), array([-0.02275538], dtype=float32)]\n",
      "None\n",
      "[array([ 1.21356797], dtype=float32), array([-0.18093495], dtype=float32)]\n",
      "None\n",
      "[array([ 1.37085438], dtype=float32), array([-0.32646015], dtype=float32)]\n",
      "None\n",
      "[array([ 1.49668348], dtype=float32), array([-0.46034336], dtype=float32)]\n",
      "None\n",
      "[array([ 1.59734678], dtype=float32), array([-0.58351588], dtype=float32)]\n",
      "None\n",
      "[array([ 1.67787743], dtype=float32), array([-0.69683462], dtype=float32)]\n",
      "None\n",
      "[array([ 1.74230194], dtype=float32), array([-0.80108786], dtype=float32)]\n",
      "None\n",
      "[array([ 1.7938416], dtype=float32), array([-0.89700085], dtype=float32)]\n",
      "None\n",
      "[array([ 1.83507323], dtype=float32), array([-0.98524082], dtype=float32)]\n",
      "None\n",
      "[array([ 1.86805856], dtype=float32), array([-1.06642151], dtype=float32)]\n",
      "None\n",
      "[array([ 1.89444685], dtype=float32), array([-1.1411078], dtype=float32)]\n",
      "None\n",
      "[array([ 1.9155575], dtype=float32), array([-1.2098192], dtype=float32)]\n",
      "None\n",
      "[array([ 1.932446], dtype=float32), array([-1.27303362], dtype=float32)]\n",
      "None\n",
      "[array([ 1.94595683], dtype=float32), array([-1.33119094], dtype=float32)]\n",
      "None\n",
      "[array([ 1.95676541], dtype=float32), array([-1.38469565], dtype=float32)]\n",
      "None\n",
      "[array([ 1.96541238], dtype=float32), array([-1.43392003], dtype=float32)]\n",
      "None\n",
      "[array([ 1.97232985], dtype=float32), array([-1.47920644], dtype=float32)]\n",
      "None\n",
      "[array([ 1.97786391], dtype=float32), array([-1.52086997], dtype=float32)]\n",
      "None\n",
      "[array([ 1.9822911], dtype=float32), array([-1.55920041], dtype=float32)]\n",
      "None\n",
      "[array([ 1.98583293], dtype=float32), array([-1.59446442], dtype=float32)]\n",
      "None\n",
      "[array([ 1.9886663], dtype=float32), array([-1.62690723], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99093306], dtype=float32), array([-1.65675461], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99274647], dtype=float32), array([-1.68421423], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99419713], dtype=float32), array([-1.70947707], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99535775], dtype=float32), array([-1.73271894], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99628615], dtype=float32), array([-1.7541014], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99702895], dtype=float32), array([-1.77377331], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99762321], dtype=float32), array([-1.79187143], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99809861], dtype=float32), array([-1.80852175], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99847889], dtype=float32), array([-1.82384002], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99878311], dtype=float32), array([-1.83793283], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99902654], dtype=float32), array([-1.85089815], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99922121], dtype=float32), array([-1.86282635], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99937701], dtype=float32), array([-1.87380028], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99950159], dtype=float32), array([-1.88389623], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99960124], dtype=float32), array([-1.89318454], dtype=float32)]\n",
      "None\n",
      "[array([ 1.999681], dtype=float32), array([-1.90172982], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99974477], dtype=float32), array([-1.90959144], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99979579], dtype=float32), array([-1.9168241], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99983668], dtype=float32), array([-1.92347813], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99986935], dtype=float32), array([-1.92959988], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99989545], dtype=float32), array([-1.93523192], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99991632], dtype=float32), array([-1.94041336], dtype=float32)]\n",
      "None\n",
      "[array([ 1.999933], dtype=float32), array([-1.9451803], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99994636], dtype=float32), array([-1.94956589], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99995708], dtype=float32), array([-1.95360065], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99996567], dtype=float32), array([-1.95731258], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99997258], dtype=float32), array([-1.96072757], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99997807], dtype=float32), array([-1.96386933], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99998248], dtype=float32), array([-1.9667598], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99998593], dtype=float32), array([-1.969419], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99998879], dtype=float32), array([-1.97186553], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999106], dtype=float32), array([-1.97411633], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999285], dtype=float32), array([-1.97618699], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999428], dtype=float32), array([-1.97809207], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999547], dtype=float32), array([-1.97984469], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999642], dtype=float32), array([-1.98145711], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999714], dtype=float32), array([-1.98294055], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999774], dtype=float32), array([-1.98430526], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999821], dtype=float32), array([-1.98556089], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999857], dtype=float32), array([-1.98671603], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999881], dtype=float32), array([-1.98777878], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999905], dtype=float32), array([-1.98875654], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999928], dtype=float32), array([-1.98965597], dtype=float32)]\n",
      "None\n",
      "[array([ 1.9999994], dtype=float32), array([-1.99048352], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999952], dtype=float32), array([-1.99124479], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999964], dtype=float32), array([-1.99194527], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99258971], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99318254], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99372792], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99422967], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99469125], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.995116], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99550676], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99586618], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99619687], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99650109], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99678099], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99703848], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99727535], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99749327], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99769378], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99787831], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99804807], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99820423], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99834788], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99848008], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99860168], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99871349], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99881637], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99891102], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99899817], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99907827], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99915206], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99921989], dtype=float32)]\n",
      "None\n",
      "[array([ 1.99999976], dtype=float32), array([-1.99928236], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)    #reset the values of A and b to the previous incorrect values\n",
    "    for _ in range(100):\n",
    "        print(sess.run(train,{x:[-2,-1,1,2], y:[-6,-4,0,2]}))\n",
    "        print(sess.run([A,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the outputs above, we see that the values of **A** and **b** are getting closer to the ideal values where the **Loss Function** is minimum. After each iteration, the values of **A** and **b** improves and gets closer to **2** and **-2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
